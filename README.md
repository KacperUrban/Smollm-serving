# Smollm-serving
This project was created due to Ml-workout newsletter, where I am building my ML skills. If you want to join, feel free to use this link - https://subscribepage.io/ml-workout-materials.

In this project I wanted to use a smollm localy and create simple API. So I used a Transfomers library to load model and then I used a FastApi to create two endpoints (one for each model). Last step was to created Dockerfile. If you want to reproduce this code, please first run get_models.py scripts, then you can run Dockerfile. Or you can run Dockerfile and in container run this script.
# Techonologies
- Python
- Transfomers
- Fastapi
- PyTorch
- Docker
# Status
Project has been completed.
